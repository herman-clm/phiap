---
title: "RAR Related Raw Data"
output: html_document
---

## HERMANDA_RAR_PTS_DEMO.csv
```{r setup, include=FALSE, echo=FALSE, cache=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
library(dplyr)
library(data.table)
library(tibble)
library(tidyr)
setwd("~/repos/Daniel_Herman_Aldosterone_2017_03/code/R/PA_analysis")
source("../common_anal/RAR_fxns.R")
```

Read in patients' demographis info, HERMANDA_RAR_PTS_DEMO.csv
```{r load in data, echo=FALSE, cache=TRUE}
rar_demo <- fread(file = "/data/raw_data/PA/HERMANDA_RAR_PTS_DEMO.csv", header = TRUE, stringsAsFactors = FALSE)
```

```{r Clean a little, dependson=c("load in data")}
rar_demo <- id_date(rar_demo)

sum(duplicated(rar_demo)) # no duplicates
```

```{r EMPI ~ PK_PATIENT_ID}
rar_demo %>% group_by(EMPI) %>%
  summarise(N=n_distinct(PK_PATIENT_ID)) %>%
  filter(N != 1)
```
There are 4 EMPI's having more than 1 PK_PATIENT_ID
```{r EMPI with more than 1 PK_PATIENT_ID}
temp <- rar_demo %>% group_by(EMPI) %>%
  summarise(N=n_distinct(PK_PATIENT_ID)) %>%
  filter(N != 1)
rar_demo %>% filter(EMPI %in% temp$EMPI) %>%
  group_by(EMPI) %>%
  arrange(EMPI, GENDER_MASTER_CODE, desc(RACE_MASTER_CODE)) %>%
  filter(row_number() == n())

tp <- rar_demo %>% group_by(EMPI) %>%
  arrange(EMPI, GENDER_MASTER_CODE, desc(RACE_MASTER_CODE)) %>%
  filter(row_number() == n())
```
In tp, EMPI and PK_PATIENT_ID are 1 to 1 match.


## HERMANDA_RAR_PTS.csv
```{r Read in RAR_PTS}
rar_pts <- fread(file = "/data/raw_data/PA/HERMANDA_RAR_PTS.csv", header = TRUE, stringsAsFactors = FALSE)

```



## HERMANDA_RAR_PTS_DX.csv
```{r Read in RAR_PTS_DX}
rar_dx <- fread(file = "/data/raw_data/PA/HERMANDA_RAR_PTS_DX.csv", header = TRUE, stringsAsFactors = FALSE)
```

```{r check dups}
sum(duplicated(rar_dx))

source("../common_anal/ALDO_Dx_fxns.R")

temp <- dup_dx_pk_YN(rar_dx)

# Apply my function to remove dups in PK_ENCOUNTER_ID level
# rar_dx <- dup_dx_pk_RM(rar_dx)
# Got the ERROR: Mismatch CONNENT
```
No duplicated rows. But there are lots of duplicated Dx's in PK_ENCOUNTER_ID level.




ICD 9 or ICD 10?
```{r ICD9/10}
table(rar_dx$CODE_STANDARD_NAME)
```
There are many Dx's without indicator for ICD.
```{r no ICD indicator}
rar_dx %>% filter(CODE_STANDARD_NAME == "") %>%
  group_by(CODE) %>%
  summarise(N=n()) %>%
  print.data.frame()
```
They also do not have ICD CODE's. So remove them...


```{r check Dx's/Unique}
length(unique(rar_dx$CODE))
length(unique(rar_dx$PK_DX_ID)) # Unique to this table
```
```{r DESCRIPTION?}
rar_dx %>% filter(CODE %in% c("255.1", "255.11")) %>% 
  group_by(CODE, DESCRIPTION) %>%
  summarise(n())
```
Description are still like part of CODE.
```{r DESCRIPTION and COMMENTS?}
rar_dx %>% filter(CODE %in% c("255.1", "255.11")) %>% 
  group_by(CODE, DESCRIPTION, COMMENTS) %>%
  summarise(n())
```


```{r One ICD-10 "E26.02" is missing here}
temp <- rar_dx %>% filter(CODE_STANDARD_NAME == "ICD-10" & (grepl("E26.0.", CODE) | CODE == "E26.9"))
    
temp <- rar_dx %>% filter(CODE_STANDARD_NAME == "ICD9" & CODE %in% c('255.10', '255.11', '255.1', '255.12')) %>% rbind(.,temp)
    
aldo_dx <- unique(temp$CODE)
aldo_dx
```



HAR_NUMBER:
```{r HAR_NUMBER missing}
sum(is.na(rar_dx$HAR_NUMBER))
```

Almost half of ALDO Dx's has a missing HAR_NUMBER, so could not just remove them
```{r HAR_NUMBER missing for ALDO}
rar_dx %>% filter(CODE %in% aldo_dx) %>%
  summarise(N=n())
rar_dx %>% filter(CODE %in% aldo_dx & is.na(HAR_NUMBER)) %>%
  summarise(N=n())
```

```{r Create HAR}
rar_dx <- load_RAR_Dx()

  
ret <- tibble()
  

# get ALDO Dx's, in a higher level
  
# catch Hyperaldo in a higher level
ret <- dat %>% filter(CODE_STANDARD_NAME == "ICD-10" & grepl("E26\\.*", CODE))
     
ret <- dat %>% filter(CODE_STANDARD_NAME == "ICD9" & grepl("255\\.1", CODE)) %>% rbind(.,ret)
      
aldo_dx <- unique(ret$CODE)
nd <- length(unique(ret$CODE))
    
# get HTN Dx's, in a higher level

ret <- dat %>% filter(CODE_STANDARD_NAME == "ICD-10" & grepl("I10|I15", CODE))
    
ret <- dat %>% filter(CODE_STANDARD_NAME == "ICD9" & grepl("401|405", CODE)) %>% rbind(.,ret)
    

ret$HAR <- ifelse(is.na(ret$HAR_NUMBER), 
                        paste(ret$EMPI, format(ret$ENC_DATE, "%Y-%m-%d")),
                        ret$HAR_NUMBER)

```

```{r For Each HAR, check dups in CODE}
ret %>% group_by(HAR) %>% 
  summarise(N=n_distinct(CODE)) %>%
  filter(N != 1)
```
Take a look into those HAR with more than 1 CODE
```{r HAR "1000902293 2003-09-26" "10001616218"}
ret %>% filter(HAR == "1000902293 2003-09-26")
ret %>% filter(HAR == "10001616218") %>% arrange(PRIMARY_YN)

```
So:
(1) Pick PRIMARY_YN = TRUE, [first of desc(PRIMARY_YN)]
(2) DX_SEQUENCE minimal [first of arrange(DX_SEQUENCE), NA will be last]
(3) First of arrange(desc(SOURCE_LAST_UPDATE_DATE), desc(COMMENTS)) [This will avoid "" in COMMENTS]


Question: For each HAR, are all Dx's on the same day?
```{r HAR with multiple Dates}
ret %>% group_by(HAR) %>%
  summarise(N = n_distinct(format(ENC_DATE, "%Y-%m-%d"))) %>%
  filter(N != 1)

```
There are 29 HAR's which have Dx's in different days.



## HERMANDA_RAR_PTS_ENC.csv
```{r Read in RAR_PTS_ENC}
rar_enc <- fread(file = "/data/raw_data/PA/HERMANDA_RAR_PTS_ENC.csv", header = TRUE, stringsAsFactors = FALSE)
```

```{r Check dups}
sum(duplicated(rar_enc))
```
No dups.


```{r Remove data}

# Keep "OUTPATIENT"
rar_enc %<>% filter(PATIENT_MASTER_CLASS == "OUTPATIENT")

# Remove those with 1/2 BP missing
rar_enc %<>% filter(!(is.na(BP_SYSTOLIC) | is.na(BP_DIASTOLIC))) %>%
      select(EMPI, PK_ENCOUNTER_ID, ENC_DATE, E_SOURCE_LAST_UPDATE, HAR_NUMBER, 
             BP_SYSTOLIC, BP_DIASTOLIC)

rar_enc <- id_date(rar_enc)

# Create new HAR: HAR_NUMBER or EMPI + ENC Date
rar_enc$HAR <- ifelse(is.na(rar_enc$HAR_NUMBER), 
                        paste(rar_enc$EMPI, format(rar_enc$ENC_DATE, "%Y-%m-%d")),
                        rar_enc$HAR_NUMBER)

length(unique(rar_enc$HAR))
```

```{r Collapse into HAR Level}

rar_enc %<>% group_by(HAR) %>%
      arrange(desc(E_SOURCE_LAST_UPDATE)) %>%
      mutate_at(vars(BP_SYSTOLIC:BP_DIASTOLIC), funs(median(., na.rm = FALSE))) %>%
      slice(1) %>%
      ungroup()
```



## HERMANDA_RARV3.csv
```{r Read in RAR_PTS_ENC}
rar <- load_RAR_v3()


```
```{r Check dups}
sum(duplicated(rar))
```
No dups.



## HERMANDA_RAR_PTS_LABS.csv
```{r Read in RAR_PTS_LABS}
rar_lab <- fread(file = "/data/raw_data/PA/HERMANDA_RAR_PTS_LABS.csv", header = TRUE, stringsAsFactors = FALSE)
```

```{r  Dups}
sum(duplicated(rar_lab))
```
No dups.

```{r RESULT STATUS}
rar_lab %>% group_by(RESULT_STATUS) %>%
  summarise(N = n()) %>% 
  arrange(desc(N))
```
There are several Result Status besides of "Final".
TODO: Validate "Final"s are good to use

Now take a subset of "Final" from RESULT_STATUS:
```{r subset RESULT_STATUS == "Final"}
rar_lab %<>% filter(RESULT_STATUS == "Final")
```


```{r Whats Left in Labs}
rar_lab %>% group_by(RESULT_ITEM_CODE) %>%
  summarise(N = n()) %>% 
  print.data.frame()
```

```{r Catch "ALDO|RENIN"}
# catch "ALDO"|"RENIN"
rar_lab %>% filter(grepl("renin|aldo", tolower(RESULT_ITEM_CODE))) %>%
  group_by(ORDER_NAME,RESULT_ITEM_CODE) %>%
  summarise(N = n()) %>%
  print.data.frame()


rar_lab_ra <-  rar_lab %>% filter(grepl("renin|aldo", tolower(RESULT_ITEM_CODE))) %>%
  group_by(ORDER_ITEM_CODE, RESULT_ITEM_CODE)



```

Exclude some AVS or urine specimens
```{r Exclude ORDER_ITEM_CODE that are for AVS or urine specimens}
rar_lab_ra %<>% filter(!(ORDER_ITEM_CODE %in%  c("C9009900", "C9009995", "C9009997", "Q19573", "83497A")))

rar_lab_ra$RESULT_VALUE <- numericize(rar_lab_ra$RESULT_VALUE, adjust_up = 1.5, adjust_down = 0.5)


table(rar_lab_ra$ORDER_ITEM_CODE)
```

```{r Check ORDER ~ RESULT}
rar_lab_ra %>% group_by(ORDER_ITEM_CODE, ORDER_NAME, RESULT_ITEM_CODE) %>%
  summarise(N=n())

rar_lab_ra %>% group_by(RESULT_ITEM_CODE, ORDER_ITEM_CODE) %>%
  summarise(N=n())


rar_lab_ra %>% group_by(RESULT_ITEM_CODE) %>%
  summarise(N=n())

rar_lab_ra %>% group_by(RESULT_ITEM_CODE, tolower(UNIT_OF_MEASURE)) %>%
  summarise(N=n())
```

```{r Modify Based on RESULT_ITEM_CODE}
ret <- as.tibble()

# dropped many rows here
ret <- rar_lab_ra %>% 
  filter(RESULT_ITEM_CODE %in% c("RENIN ACTIVITY","RENIN", "PLASMA RENIN ACTIVITY, LC/MS/MS", "PLASMA RENIN ACTIVITY")) %>%
    mutate(Test = "PRA")


ret <- rar_lab_ra %>% 
  filter(RESULT_ITEM_CODE %in% c("DIRECT RENIN")) %>% 
  mutate(Test = "DRC") %>%
  rbind(., ret)

ret <- rar_lab_ra %>% 
  filter(RESULT_ITEM_CODE %in% c("ALDOSTERONE, SERUM", "ALDOSTERONE, LC/MS/MS", "ALDOSTERONE")) %>%
  mutate(Test = "Aldo") %>%
  rbind(., ret)

table(ret$Test)
```

Collapse
```{r HAR on Labs}
ret <- id_date(ret)
# Create HAR
ret$HAR <- ifelse(is.na(ret$HAR_NUMBER), 
                        paste(ret$EMPI, format(ret$ENC_DATE, "%Y-%m-%d")),
                        ret$HAR_NUMBER)


```

```{r Pair Test Results}
sum(duplicated(ret$PK_ORDER_ID))
sum(duplicated(ret$HAR))

ret %>% group_by(HAR) %>%
  summarise(N = n()) %>%
  filter(N > 2) %>%
  arrange(desc(N))

```

HOW TO FIND ALDO ~ RENIN pairs???
```{r Try pair}
aldo <- ret %>% filter(Test == "Aldo")
renin <- ret %>% filter(Test == "DRC" | Test == "PRA")

length(unique(intersect(aldo$HAR, renin$HAR))) # 6790




# Each PK_ORDER_ID only contain one ENC_DATE
ret %>% group_by(PK_ORDER_ID) %>%
  summarise(N = n_distinct(ENC_DATE)) %>%
  filter(N != 1)
# returns 0

# Each patient could have multiple Lab Tests ordered in one day
ret %>% group_by(EMPI, ENC_DATE, Test) %>%
  summarise(N = n_distinct(PK_ORDER_ID)) %>%
  filter(N != 1)
# returns 315 rows
# TODO: filter out saline suppression tests, AVS, ...


# Each HAR could have multiple Lab Test Orders
ret %>% 
  group_by(HAR, Test) %>%
  summarise(N = n_distinct(PK_ORDER_ID)) %>%
  filter(N != 1)
#316
```

```{r Group by HAR + PK_ORDER_ID, then take the mean for multiples}
# drop a few columns
aldo %<>% 
  select(EMPI, PK_ENCOUNTER_ID, ENC_DATE, HAR_NUMBER, HAR, PK_ORDER_ID, ORDER_ITEM_CODE, RESULT_STATUS, RESULT_ITEM_CODE, Test, RESULT_VALUE, UNIT_OF_MEASURE) %>%
  mutate(Aldo = RESULT_VALUE) %>%
  select(-c(Test, RESULT_VALUE, UNIT_OF_MEASURE))

renin %<>% 
  select(EMPI, PK_ENCOUNTER_ID, ENC_DATE, HAR_NUMBER, HAR, PK_ORDER_ID, ORDER_ITEM_CODE, RESULT_STATUS, RESULT_ITEM_CODE, Test, RESULT_VALUE, UNIT_OF_MEASURE) %>%
  mutate(PRA = ifelse(Test == "PRA", RESULT_VALUE, NA), DRC = ifelse(Test == "DRC", RESULT_VALUE, NA)) %>%
  select(-c(Test, RESULT_VALUE, UNIT_OF_MEASURE))

# aggregate in PK_ORDER_ID
## For same PK_ORDER_ID, they will have same ENC_DATE
aldo %<>% 
  group_by(EMPI, HAR, ENC_DATE, PK_ORDER_ID) %>%
  summarise(Aldo = mean(Aldo, na.rm = TRUE))

renin %<>% 
  group_by(HAR, EMPI, PK_ORDER_ID, ENC_DATE) %>%
  summarise(PRA = mean(PRA, na.rm = TRUE), 
            DRC = mean(DRC, na.rm=TRUE))

```


```{r collapse_levels}

tmp <- ret %>%
  ungroup() %>%
          select(EMPI, PK_ENCOUNTER_ID, ENC_DATE, HAR, PK_ORDER_ID, Test, RESULT_VALUE, RESULT_DATE, O_SOURCE_LAST_UPDATE, ORDER_START_DATE)
tmp %>% summarize(N_rows = n(), N_distinct_enc = n_distinct(EMPI, PK_ENCOUNTER_ID), N_distinct_collects = n_distinct(EMPI, ORDER_START_DATE), N_distinct_HAR = n_distinct(HAR))

# Summarize at PK_ORDER_ID (QC) (--> PK_ORDER_ID level)
# TODO: make sure we are picking the best result
tmp %<>%
  group_by(EMPI, PK_ENCOUNTER_ID, ENC_DATE, HAR, PK_ORDER_ID, Test) %>%
  arrange(desc(RESULT_DATE), desc(O_SOURCE_LAST_UPDATE)) %>%
  slice(1) %>% ungroup()
tmp %>% summarize(N_rows = n(), N_distinct_enc = n_distinct(EMPI, PK_ENCOUNTER_ID), N_distinct_collects = n_distinct(EMPI, ORDER_START_DATE), N_distinct_HAR = n_distinct(HAR))

# -> ret at unique PK_ORDER_ID level

# # Exploring multiple test per ENCOUNTER scenarios
# tmp %>%
#   group_by(EMPI, PK_ENCOUNTER_ID, Test) %>%
#   filter(n() > 1) %>%
#   mutate(N=row_number()) %>%
#   ungroup() %>%
#   arrange(EMPI, PK_ENCOUNTER_ID, Test, N)

# Summarize at Collect Time (--> EMPI + ORDER_START_DATE level)
# Note:In EMPI + ORDER_START_DATE (PK_ENCOUNTER_ID + ORDER_START_DATE) level, dups for tests (like two ALDO tests with same ORDER_START_DATE), pick one based on RESULT_DATE and O_SOURCE_LAST_UPDATE
# TODO: make sure we are picking the best result
tmp %<>%
  group_by(EMPI, PK_ENCOUNTER_ID, ENC_DATE, HAR, ORDER_START_DATE, Test) %>%
  arrange(desc(RESULT_DATE), desc(O_SOURCE_LAST_UPDATE)) %>%
  slice(1) %>%
  ungroup()
tmp %>% summarize(N_rows = n(), N_distinct_enc = n_distinct(EMPI, PK_ENCOUNTER_ID), N_distinct_collects = n_distinct(EMPI, ORDER_START_DATE), N_distinct_HAR = n_distinct(HAR))


# Start to Collapse on PK_ENCOUNTER_ID level
# Pair based on Collect Time
## Spread tmp into wide first
## After spreading, for each EMPI - PK_ENCOUNTER_ID - ORDER_START_DATE, there will be only one row (containing 3 tests)
tmp %<>%
  select(EMPI, PK_ENCOUNTER_ID, ENC_DATE, HAR, ORDER_START_DATE, Test, RESULT_VALUE) %>%
  group_by(EMPI, PK_ENCOUNTER_ID, ENC_DATE, HAR, ORDER_START_DATE) %>%
  spread(key = Test, value=RESULT_VALUE) %>% ungroup()
tmp %>% summarize(N_rows = n(), N_distinct_enc = n_distinct(EMPI, PK_ENCOUNTER_ID), N_distinct_collects = n_distinct(EMPI, ORDER_START_DATE), N_distinct_HAR = n_distinct(HAR))

# Could join back to get more columns

# Exploring multiple test per ENCOUNTER scenarios
tmp %>%
  group_by(EMPI, PK_ENCOUNTER_ID) %>%
  filter(n() > 1) %>%
  mutate(N=row_number()) %>%
  ungroup() %>%
  arrange(EMPI, PK_ENCOUNTER_ID, N)

# Merge if collect within 30 minutes
tmp_merged_2 <- tmp %>%
  group_by(EMPI, PK_ENCOUNTER_ID, ENC_DATE, HAR) %>%
  filter(n() == 2,
         abs(ORDER_START_DATE[1] - ORDER_START_DATE[2]) < 60*30) %>%  # merge if within 30 minutes 
  mutate_at(vars(Aldo:DRC), funs(na.omit(.)[1])) %>%
  slice(1) %>% ungroup()

# Take first row if 2 rows (far apart in time) or >2 rows
tmp_merged_multi <- tmp %>%
  group_by(EMPI, PK_ENCOUNTER_ID, ENC_DATE, HAR) %>%
  filter((n() == 2 & abs(ORDER_START_DATE[1] - ORDER_START_DATE[2]) >= 60*30) |
           n() > 2) %>%  # merge if within 30 minutes 
  arrange(ORDER_START_DATE) %>%
  slice(1) %>% ungroup()

# Combine with single row data (--> PK_ENCOUNTER_ID level)
tmp %<>%
  group_by(EMPI, PK_ENCOUNTER_ID, ENC_DATE, HAR) %>%
  filter(n() == 1) %>%
  ungroup() %>%
  bind_rows(tmp_merged_2) %>%
  bind_rows(tmp_merged_multi)
tmp %>% summarize(N_rows = n(), N_distinct_enc = n_distinct(EMPI, PK_ENCOUNTER_ID), N_distinct_collects = n_distinct(EMPI, ORDER_START_DATE), N_distinct_HAR = n_distinct(HAR))




# Start to Collect at the HAR level
# TODO: Resolve the collect times at 00:00:00 (Get Inlab or received ttime to help)

# (1) dates are same and one of each -> merge
# (2) dates are same and more than one of one of them, drop
# (3) dates are different, pick first one

# Explore multiple PK_ENCOUNTER_ID's in HAR level
temp <- tmp %>% group_by(HAR) %>%
          filter(n() != 1) %>%
          arrange(HAR)



## (1) (2)
temp_12 <- temp %>% group_by(HAR) %>% filter(n_distinct(ORDER_START_DATE) == 1) %>% ungroup()

temp_12 %<>% group_by(HAR) %>% 
              filter(n_distinct(Aldo, na.rm = TRUE) %in% c(0,1) & 
                       n_distinct(DRC, na.rm = TRUE) %in% c(0,1) & 
                       n_distinct(PRA, na.rm = TRUE) %in% c(0,1)) %>%
              mutate_at(vars(Aldo:DRC), funs(na.omit(.)[1])) %>%
              slice(1) %>% ungroup()

## (3)
temp_3 <- temp %>% group_by(HAR) %>%
            filter(n_distinct(ORDER_START_DATE) != 1) %>%
            arrange(ORDER_START_DATE) %>%
            slice(1) %>%
            ungroup()

## Merge temp_12 & temp_3 back to tmp
tmp %<>% group_by(HAR) %>%
  filter(n() == 1) %>%
  bind_rows(temp_12, temp_3) %>%
  ungroup()
tmp %>% summarize(N_rows = n(), N_distinct_enc = n_distinct(EMPI, PK_ENCOUNTER_ID), N_distinct_collects = n_distinct(EMPI, ORDER_START_DATE), N_distinct_HAR = n_distinct(HAR))

# A check on Patients with different HAR's but same ORDER_START_DATE's
tmp %>% group_by(EMPI, ORDER_START_DATE) %>% filter(n() != 1)

```




## Merge Demo, Dx, Enc, Labs
```{r Load}
load("bios_data.RData")
```


```{r Check Common HAR's}
# Note: n_distinct is very slow here
# rar_enc %>% summarise(ENC_HAR = n_distinct(HAR))

length(unique(rar_enc$HAR)) # 231610
length(unique(rar_dx$HAR)) # 153682
length(unique(rar_lab$HAR)) # 8810
length(unique(rar_demo$EMPI)) # 7137



HAR_common <- Reduce(intersect, list(unique(rar_enc$HAR), unique(rar_lab$HAR)))

length(unique(HAR_common)) # 3068

# check Which rar_lab HAR is not in rar_enc HAR
temp <-  setdiff(rar_lab$HAR, rar_enc$HAR)

# check those in original ENC data
enc_ori <- fread("/data/raw_data/PA/HERMANDA_RAR_PTS_ENC.csv", header = TRUE, stringsAsFactors = FALSE)

View(enc_ori[HAR_NUMBER == "201259167"])
View(enc_ori[EMPI == 1000010437]) # This patient does not have BP's for this HAR so it's got dropped...

enc_ori[HAR_NUMBER == "415298801"]

# Fix to keep all ENC data (do not exclude those without BP's)

```

```{r Merge}

load("bios_data.RData")
# From here, we no longer use HAR. Use EMPI_DATE instead.


rar_enc %<>% select(-c(E_SOURCE_LAST_UPDATE, PK_ENCOUNTER_ID, ENC_DATE))
rar_dx %<>% select(-c(EMPI, CODE_STANDARD_NAME, COMMENTS, CODING_DATE, PRIMARY_YN, DX_SEQUENCE,DESCRIPTION, PK_DX_ID, SOURCE_LAST_UPDATE_DATE, ENC_DATE, PK_ENCOUNTER_ID, DX_TYPE, HAR_NUMBER))
rar_lab %<>% select(-c(EMPI, PK_ENCOUNTER_ID))

length(unique(rar_enc$EMPI_DATE)) # 1300052
length(unique(rar_dx$EMPI_DATE)) #  149715
length(unique(rar_lab$EMPI_DATE)) # 8801
length(unique(rar_demo$EMPI)) # 7137




# spread rar_dx
rar_dx %<>% mutate(value = 1) %>%
  spread(CODE, value, fill = 0)
## QC: check whether rar_dx has unique rows regarding to EMPI_DATE
length(unique(rar_dx$EMPI_DATE)) == dim(rar_dx)[1]  # TRUE

## Full Join: keep all info
rar_mg <- rar_dx %>% full_join(., rar_enc, by = "EMPI_DATE") %>% full_join(., rar_lab, by = "EMPI_DATE") %>% full_join(., rar_demo, by="EMPI")

## For NA's in Dx, change them into 0
rar_mg[,4:22] <- lapply(rar_mg[,4:22], function(x) x=ifelse(is.na(x), 0, x))
  

## QC: check the merging results
dim(rar_mg)[1]  # 1298404 One more than ENC, because one lab's EMPI_DATE is not in enc's ----> See below
length(unique(rar_mg$EMPI_DATE)) == dim(rar_mg)[1] # TRUE


# # remove the ones with all NA except for demo info
# temp <- apply(rar_mg[,8:26],1, function(x) return(sum(is.na(x)) == 17))



```

## Patient Level
```{r Overview}
length(unique(rar_mg$EMPI_DATE)) # 1300052
length(unique(rar_mg$EMPI)) # 5677


rar_mg %>% group_by(EMPI) %>% filter(n() == 2) %>% View()

```


```{r BPs and RAR Tests}
pts <- rar_mg

## SBP_n, DBP_n, High_BP_n
pts %<>% group_by(EMPI) %>% 
        mutate(SBP_n = sum(BP_SYSTOLIC >= 140, na.rm = TRUE), DBP_n = sum(BP_DIASTOLIC >= 90, na.rm = TRUE))

pts %<>% group_by(EMPI) %>% 
        mutate(High_BP_n = sum(BP_SYSTOLIC >= 140 | BP_DIASTOLIC >= 90, na.rm = TRUE))

## Drop BP's
pts %<>% select(-c(BP_SYSTOLIC, BP_DIASTOLIC))


## Dx's
pts %<>% group_by(EMPI) %>%
  mutate_at(vars(`401`:I15.9), funs(sum))

## RAR
pts %<>% group_by(EMPI) %>% 
        mutate(N = (is.na(Aldo) + is.na(PRA) + is.na(DRC))) %>%
        arrange(EMPI, N, ENC_DATE) %>% 
        slice(1) %>%
        select(EMPI, PK_PATIENT_ID, GENDER_MASTER_CODE, BIRTH_DATE, RACE_MASTER_CODE, RACE_MASTER_HISPANIC_YN,ENC_DATE, `401`:I15.9, Aldo:PRA, SBP_n, DBP_n, High_BP_n)
      
# 7137 pts rows


# 
# length(unique(pts$EMPI)) == length(unique(rar_demo$EMPI)) # FALSE
# 
# # There is one more patient who is not in rar_demo...
# setdiff(pts$EMPI, rar_demo$EMPI)
# # That patient is NA?
# 
# which(is.na(rar_mg$EMPI))
# rar_mg[1298404,]
# 
# 
# # His EMPI is 1003748643
# "1003748643" %in% rar_demo$EMPI # TRUE...
# 
# "1003748643" %in% rar_mg$EMPI # TRUE...
# "1003748643" %in% rar_lab$EMPI
# 
# 
# temp <- rar_dx %>% full_join(., rar_enc, by = "EMPI_DATE") 
# 
# sum(is.na(temp$EMPI)) # 0: all dx has encounter
# 
# temp <- rar_dx %>% full_join(., rar_enc, by = "EMPI_DATE") %>% full_join(., rar_lab, by = "EMPI_DATE")
# sum(is.na(temp$EMPI)) # 1: one lab does not "have" enc
# 
# # EMPI_DATE: 1003748643 2017-03-23
# "1003748643 2017-03-23" %in% rar_lab$EMPI_DATE # TRUE: This is in Labs
# "1003748643 2017-03-23" %in% rar_enc$EMPI_DATE # FALSE: This is not in ENC
# 
# # From raw data:
# raw_enc <- fread("/data/raw_data/PA/HERMANDA_RAR_PTS_ENC.csv", header = TRUE, stringsAsFactors = FALSE)
# 
# raw_enc[EMPI == "1003748643" & grepl("2017-03-23", ENC_DATE), ] # we have his data on "2017-03-23"
# # Problem: in ENC data, selected only OUTPATIENT...
```














